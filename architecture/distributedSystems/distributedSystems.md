# Distributed Systems

## Immutable architecture

- immutablity gives you hashing comparision bonuses
- autogenerated db id's cannot be used to ID an object in a distrib system
  - it is preferred to go for naturally occuring IDs or public keys
  - this helps with the location independence property distrib systems should have
- progressive web apps might connect to different db when coming back online which will lead to consistency issues
- e.g.
  - bank statements become immutable after the month and any adjustments are added on to a new statement which makes transactions so much easier

## Databases

- db sharding is hard because of the overhead needed to determine where someone's data lies on top of allowing your database to perform efficient join or aggregation type queries
- it is best to use a db that supports sharding inherently and to relax your consistency requirements

## Policy enforcement

- doing this in a distributed env is difficult but necessary for many situations like regulated industries (finance, healthcare, etc)
- great for config validation
- [OPA](https://www.openpolicyagent.org/docs/latest/ecosystem/) (Open Policy Agent)

## [Anti-fragile architecture](https://www.se-radio.net/2020/01/episode-396-barry-oreilly-on-antifragile-architecture/)

- the show notes have lots of good resources in them
- the quality of a system is tied to its ability to withstand complexity not how well it adheres to a spec
- complexity exists outside of code
- how we can deal with complexity
  - making it someone else's problem (not great)
  - try to identify patterns even if they aren't there (we can easily fool ourselves into thinking it is even possible to understand systems that are complex which is dishonest to ourselves)
  - think of processes as flows, not user requirements (helps break down architecture and modularize it)
- flows
  - this is the basic unit of work in an info system
  - start with stressors like when a competitor drops price, not with features
  - build a path to handle stressors but build in the typical "switch" to deal with unexpected events if you can
  - discussing what happens if fire breathing lizards storm the country helps guide the conversation not on focusing on probability but stressors
    - if you can make your system resilient to this problem, you inadvertantly solve dozens of others you never predicted like social unrest, war, hurricanes, datacenter outages
  - look for dependencies between flows to determine relatedness
  - group components and flows that are impacted by the same stressors
- really good properties every antifragile system has
  1. weakly linked
  2. modularity
  3. redundant
  4. diversity
  - whenever we change something about an existing system, we always change something related to one of these areas
- as an architect, you need to understand the business
  - what happens when a competitor drops their price? (answering this can reveal a lot about what is important to a business and how it works)
- resilient systems are birthed by stress, not by design
  - requirements inherently make a system fragile
- its ok not to know everything
  - complex systems are exactly that and no experienced group of people can predict anything no matter how experienced they are
- everyone has a different viewpoint on complexity and what is considered complex

## Job cancellation

- in a distributed system, you don't know which host received the request for the job, or which host is processing the job
- if you load balance the request using a hash of some job id, you can guarantee that the same host will receive all requests for a given job
  - this requires extra configuration in the load balancing layer of course
- grpc is better for cancelling due to it's two way communication channel
  - doesn't scale well at layer 4

## Clocks

- can never count on perfect clock synchronization and doing so will cause a lot of odd bugs like witnessing time going "backwards" in a system when a machine updates its time when syncing with an NTP server
- clock drift has been shown to be influenced by machine temperature
- wall clock time
  - this is a clock that's based on what we humans are used to
  - this needs an NTP server to sync with
  - when syncing with an NTP server, the clock might speed up or slow down to preserve ordering and resync overtime
    - this is called _slew_
  - if a machine is firewalled from its NTP server, the clock will continue to drift silently
  - multiple NTP servers are often used to mitigate a single point of failure
- monotonic clock
  - this uses a counter local to a machine to establish ordering of events
  - this has no relation to wall clock time
  - comparing values across machines is useless
  - these are good for timeouts
- leap seconds
  - these can be _smeared_ over time to preserve ordering
- clock reseting
  - mobile devices have the ability to change their clock
  - should not be trusted because of cases where it is advantageous for a person to change time like in gaming
- pauses
  - when running on a vm, the application will experience gaps in time caused by pauses for other applications to use the vm
  - garbage collection pauses are common in languages that use them and can last minutes sometimes
- syncing clocks
  - some situations need to have some sort of clock syncing to make the system easier to deal with like financial systems that need some guarantee of time and distributed databases that need transaction ordering
  - you need to monitor all nodes and their clock skew
  - if a node has too much clock skew, immediately remediate by fixing or killing the node to prevent problems

## [Never make these assumptions](https://www.youtube.com/watch?v=gfh-VCTwMw8&ab_channel=NDCConferences)

1. the network is reliable

   - sometimes connections are only reliable in one direction (sometimes happens with misconfigured switches)

1. latency is zero
1. bandwidth is infinite
1. the network is secure
1. topology doesn't change
1. there is one administrator
1. transport cost is zero
1. the network is homogeneous
1. you trust each other

## Performance guarantees

- GC pauses are a nightmare for services that need to provide some guarantee of performance or latency or something of the like
- some services get around this, like those in the financial sector, that tell the clients to hold off on calling them when they see it is almost time for a GC pause, and when they can get a break, they garbage collect, then resume service
- the network being unreliable makes this very difficult
  - you would need a circuit switching network in order to provide any timing, bandwidth, or like guarantee
  - these are expensive and wasteful in practice however

## Safety vs liveness properties

- there are different properties distributed systems/algorithms can have
- these are important to understand because they make it easy to reason about the correctness of a distributed system/algorithm
- these properties always have some assumptions assigned to them
  - there are just too many edge cases
  - sometimes you need to bail out to human intervention to handle the things that in the real world happen, but in theory can haver happen
    - application code can also handle these cases
  - e.g. what if a node loses all of the data it owns? (i.e. anmesia)
- the whole point of these properties is that they provide grounds for reasoning about a complicated system/algorithm

### Safety

- this is a guarantee that something bad cannot happen

### Liveness

- this is a guarantee that something good will eventually happen

## Communication channels

- it is possible for data to propogate faster on one channel than another
- this is very reasonable for the plethora of ways a network can fail or degrade
- e.g. a service writes a value to an eventually consistent database and publishes a message to a message queue
  - it is possible that some service on the receiving end of the message queue will receive the message before the replica it queries to get the value has the most recent write
- in short, you can't guarantee that data will be consistent by the time a message is received on the receiving end of one of these channels
- you need to provide some guarantee like linearizability to make this work

## Idempotence

- a very good property to have as it improve fault tolerance
- it does rely on the system to preserve order, be deterministic, and no other node can update thee same value
- can create exactly once semantics using this

## Misc

- relaxing constraints on the business requirements can lead to opportunities like amazon overselling items, but handing out gift cards when they can't fulfill everything
